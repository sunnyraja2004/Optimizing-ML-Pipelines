{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtSboBcS4-mV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Flatten, Dense\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from collections import Counter\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from scipy.sparse import csr_matrix, hstack\n",
        "import itertools\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.layers import LeakyReLU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Hpow34m5K70"
      },
      "outputs": [],
      "source": [
        "train_seq_df = pd.read_csv(\"train_text_seq.csv\")\n",
        "train_seq_X = train_seq_df['input_str'].tolist()\n",
        "train_seq_Y = np.array(train_seq_df['label'].tolist())\n",
        "\n",
        "val_seq_df = pd.read_csv(\"valid_text_seq.csv\")\n",
        "val_seq_X = val_seq_df['input_str'].tolist()\n",
        "val_seq_Y = np.array(val_seq_df['label'].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7k6TvP35NN5"
      },
      "outputs": [],
      "source": [
        "train_seq_X_list = [[int(digit) for digit in seq] for seq in train_seq_X]\n",
        "val_seq_X_list = [ [int(digit) for digit in seq] for seq in val_seq_X]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8huBnSk75R6I"
      },
      "outputs": [],
      "source": [
        "def one_hot_encode_sequence_flat(X):\n",
        "    # Initialize an empty list to store the one-hot encoded vectors\n",
        "    one_hot_encoded_flat = []\n",
        "\n",
        "    for sequence in X:\n",
        "        one_hot = np.zeros((len(sequence), 10))  # Create a 50x10 matrix for each string\n",
        "        for i, digit in enumerate(sequence):\n",
        "            one_hot[i, digit] = 1  # Set the corresponding digit index to 1\n",
        "        one_hot_flat = one_hot.flatten()\n",
        "        one_hot_encoded_flat.append(one_hot_flat)\n",
        "    return np.array(one_hot_encoded_flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMbN6ApJ5VIo"
      },
      "outputs": [],
      "source": [
        "train_seq_X_encoded = one_hot_encode_sequence_flat(train_seq_X_list)\n",
        "val_seq_X_encoded = one_hot_encode_sequence_flat(val_seq_X_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRnSOOFB5WRQ"
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "    # Input layer\n",
        "    input_shape = (50,10)\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = Conv1D(32, kernel_size=3,activation='relu', kernel_regularizer=l2(0.01))(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling1D(pool_size=4)(x)\n",
        "    x = MaxPooling1D(pool_size=2)(x)\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    # Fully connected layers\n",
        "    x = Dense(32, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
        "\n",
        "    x = Dense(32, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
        "\n",
        "    # Output layer\n",
        "    outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    # Create the model\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    optimizer = Adam(learning_rate=0.001)\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BdoCztDx5eVt"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "batch_size = 64\n",
        "epochs = 100\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Md3cs8h5fya",
        "outputId": "3823aec9-3e34-495f-d57c-48a04353fb1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5054 - loss: 1.5950 - val_accuracy: 0.5297 - val_loss: 1.2173 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5889 - loss: 1.1258 - val_accuracy: 0.6196 - val_loss: 0.9737 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7009 - loss: 0.8496 - val_accuracy: 0.6769 - val_loss: 0.8320 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7488 - loss: 0.7008 - val_accuracy: 0.7239 - val_loss: 0.7228 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7873 - loss: 0.5968 - val_accuracy: 0.7648 - val_loss: 0.6308 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8123 - loss: 0.5325 - val_accuracy: 0.8282 - val_loss: 0.5375 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8317 - loss: 0.4838 - val_accuracy: 0.7975 - val_loss: 0.5340 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8392 - loss: 0.4605 - val_accuracy: 0.8139 - val_loss: 0.4889 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8518 - loss: 0.4353 - val_accuracy: 0.8200 - val_loss: 0.4599 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8501 - loss: 0.4195 - val_accuracy: 0.8507 - val_loss: 0.4246 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8746 - loss: 0.3948 - val_accuracy: 0.8548 - val_loss: 0.4446 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8699 - loss: 0.3932 - val_accuracy: 0.8282 - val_loss: 0.4566 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8795 - loss: 0.3666 - val_accuracy: 0.8548 - val_loss: 0.4233 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8781 - loss: 0.3643 - val_accuracy: 0.8569 - val_loss: 0.4069 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8868 - loss: 0.3514 - val_accuracy: 0.8487 - val_loss: 0.4099 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8883 - loss: 0.3491 - val_accuracy: 0.8691 - val_loss: 0.3928 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8869 - loss: 0.3425 - val_accuracy: 0.8589 - val_loss: 0.3966 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8858 - loss: 0.3394 - val_accuracy: 0.8630 - val_loss: 0.3745 - learning_rate: 0.0010\n",
            "Epoch 19/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8973 - loss: 0.3219 - val_accuracy: 0.8753 - val_loss: 0.3668 - learning_rate: 0.0010\n",
            "Epoch 20/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9005 - loss: 0.3195 - val_accuracy: 0.8671 - val_loss: 0.3920 - learning_rate: 0.0010\n",
            "Epoch 21/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8942 - loss: 0.3334 - val_accuracy: 0.8630 - val_loss: 0.3863 - learning_rate: 0.0010\n",
            "Epoch 22/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9058 - loss: 0.3119 - val_accuracy: 0.8569 - val_loss: 0.3806 - learning_rate: 0.0010\n",
            "Epoch 23/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8962 - loss: 0.3221 - val_accuracy: 0.8569 - val_loss: 0.3949 - learning_rate: 0.0010\n",
            "Epoch 24/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9076 - loss: 0.2959 - val_accuracy: 0.8671 - val_loss: 0.3630 - learning_rate: 0.0010\n",
            "Epoch 25/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9002 - loss: 0.3113 - val_accuracy: 0.8732 - val_loss: 0.3647 - learning_rate: 0.0010\n",
            "Epoch 26/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9132 - loss: 0.2889 - val_accuracy: 0.8630 - val_loss: 0.3902 - learning_rate: 0.0010\n",
            "Epoch 27/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9092 - loss: 0.2931 - val_accuracy: 0.8671 - val_loss: 0.3571 - learning_rate: 0.0010\n",
            "Epoch 28/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9135 - loss: 0.2897 - val_accuracy: 0.8630 - val_loss: 0.3890 - learning_rate: 0.0010\n",
            "Epoch 29/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9186 - loss: 0.2849 - val_accuracy: 0.8712 - val_loss: 0.3667 - learning_rate: 0.0010\n",
            "Epoch 30/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9222 - loss: 0.2699 - val_accuracy: 0.8773 - val_loss: 0.3747 - learning_rate: 0.0010\n",
            "Epoch 31/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9098 - loss: 0.2894 - val_accuracy: 0.8834 - val_loss: 0.3524 - learning_rate: 0.0010\n",
            "Epoch 32/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9199 - loss: 0.2758 - val_accuracy: 0.8446 - val_loss: 0.4523 - learning_rate: 0.0010\n",
            "Epoch 33/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9173 - loss: 0.2818 - val_accuracy: 0.8793 - val_loss: 0.3553 - learning_rate: 0.0010\n",
            "Epoch 34/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9287 - loss: 0.2669 - val_accuracy: 0.8712 - val_loss: 0.3894 - learning_rate: 0.0010\n",
            "Epoch 35/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9178 - loss: 0.2798 - val_accuracy: 0.8446 - val_loss: 0.4362 - learning_rate: 0.0010\n",
            "Epoch 36/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9182 - loss: 0.2796 - val_accuracy: 0.8896 - val_loss: 0.3564 - learning_rate: 0.0010\n",
            "Epoch 37/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9385 - loss: 0.2398 - val_accuracy: 0.8834 - val_loss: 0.3557 - learning_rate: 2.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9457 - loss: 0.2304 - val_accuracy: 0.8875 - val_loss: 0.3497 - learning_rate: 2.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9459 - loss: 0.2321 - val_accuracy: 0.8855 - val_loss: 0.3493 - learning_rate: 2.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9478 - loss: 0.2296 - val_accuracy: 0.8937 - val_loss: 0.3518 - learning_rate: 2.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.2223 - val_accuracy: 0.8896 - val_loss: 0.3535 - learning_rate: 2.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9511 - loss: 0.2181 - val_accuracy: 0.8896 - val_loss: 0.3512 - learning_rate: 2.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9568 - loss: 0.2154 - val_accuracy: 0.8875 - val_loss: 0.3642 - learning_rate: 2.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9498 - loss: 0.2180 - val_accuracy: 0.8855 - val_loss: 0.3630 - learning_rate: 2.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9574 - loss: 0.2103 - val_accuracy: 0.8896 - val_loss: 0.3587 - learning_rate: 4.0000e-05\n",
            "Epoch 46/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9593 - loss: 0.2087 - val_accuracy: 0.8834 - val_loss: 0.3585 - learning_rate: 4.0000e-05\n",
            "Epoch 47/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9605 - loss: 0.2086 - val_accuracy: 0.8937 - val_loss: 0.3609 - learning_rate: 4.0000e-05\n",
            "Epoch 48/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9564 - loss: 0.2107 - val_accuracy: 0.8937 - val_loss: 0.3602 - learning_rate: 4.0000e-05\n",
            "Epoch 49/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9624 - loss: 0.2051 - val_accuracy: 0.8916 - val_loss: 0.3657 - learning_rate: 4.0000e-05\n",
            "Epoch 50/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9622 - loss: 0.2075 - val_accuracy: 0.8937 - val_loss: 0.3613 - learning_rate: 1.0000e-05\n",
            "Epoch 51/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9608 - loss: 0.2033 - val_accuracy: 0.8875 - val_loss: 0.3602 - learning_rate: 1.0000e-05\n",
            "Epoch 52/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9613 - loss: 0.2068 - val_accuracy: 0.8916 - val_loss: 0.3605 - learning_rate: 1.0000e-05\n",
            "Epoch 53/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9591 - loss: 0.2082 - val_accuracy: 0.8916 - val_loss: 0.3612 - learning_rate: 1.0000e-05\n",
            "Epoch 54/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9608 - loss: 0.2070 - val_accuracy: 0.8937 - val_loss: 0.3620 - learning_rate: 1.0000e-05\n",
            "Epoch 55/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9591 - loss: 0.2075 - val_accuracy: 0.8896 - val_loss: 0.3610 - learning_rate: 1.0000e-05\n",
            "Epoch 56/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9610 - loss: 0.2045 - val_accuracy: 0.8875 - val_loss: 0.3609 - learning_rate: 1.0000e-05\n",
            "Epoch 57/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9614 - loss: 0.2038 - val_accuracy: 0.8916 - val_loss: 0.3616 - learning_rate: 1.0000e-05\n",
            "Epoch 58/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9579 - loss: 0.2116 - val_accuracy: 0.8916 - val_loss: 0.3618 - learning_rate: 1.0000e-05\n",
            "Epoch 59/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9597 - loss: 0.2107 - val_accuracy: 0.8916 - val_loss: 0.3622 - learning_rate: 1.0000e-05\n",
            "Epoch 60/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9627 - loss: 0.2038 - val_accuracy: 0.8937 - val_loss: 0.3626 - learning_rate: 1.0000e-05\n",
            "Epoch 61/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9604 - loss: 0.2064 - val_accuracy: 0.8916 - val_loss: 0.3628 - learning_rate: 1.0000e-05\n",
            "Epoch 62/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9638 - loss: 0.2033 - val_accuracy: 0.8896 - val_loss: 0.3625 - learning_rate: 1.0000e-05\n",
            "Epoch 63/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9609 - loss: 0.2082 - val_accuracy: 0.8937 - val_loss: 0.3639 - learning_rate: 1.0000e-05\n",
            "Epoch 64/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9627 - loss: 0.2059 - val_accuracy: 0.8916 - val_loss: 0.3632 - learning_rate: 1.0000e-05\n",
            "Epoch 65/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9616 - loss: 0.2047 - val_accuracy: 0.8875 - val_loss: 0.3624 - learning_rate: 1.0000e-05\n",
            "Epoch 66/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9596 - loss: 0.2077 - val_accuracy: 0.8875 - val_loss: 0.3626 - learning_rate: 1.0000e-05\n",
            "Epoch 67/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9630 - loss: 0.2020 - val_accuracy: 0.8875 - val_loss: 0.3627 - learning_rate: 1.0000e-05\n",
            "Epoch 68/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9615 - loss: 0.2013 - val_accuracy: 0.8937 - val_loss: 0.3639 - learning_rate: 1.0000e-05\n",
            "Epoch 69/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9608 - loss: 0.2075 - val_accuracy: 0.8916 - val_loss: 0.3642 - learning_rate: 1.0000e-05\n",
            "Epoch 70/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9601 - loss: 0.2080 - val_accuracy: 0.8875 - val_loss: 0.3633 - learning_rate: 1.0000e-05\n",
            "Epoch 71/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9626 - loss: 0.2044 - val_accuracy: 0.8937 - val_loss: 0.3648 - learning_rate: 1.0000e-05\n",
            "Epoch 72/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9627 - loss: 0.2017 - val_accuracy: 0.8916 - val_loss: 0.3643 - learning_rate: 1.0000e-05\n",
            "Epoch 73/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9574 - loss: 0.2095 - val_accuracy: 0.8855 - val_loss: 0.3633 - learning_rate: 1.0000e-05\n",
            "Epoch 74/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9621 - loss: 0.2016 - val_accuracy: 0.8855 - val_loss: 0.3636 - learning_rate: 1.0000e-05\n",
            "Epoch 75/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9652 - loss: 0.1972 - val_accuracy: 0.8875 - val_loss: 0.3642 - learning_rate: 1.0000e-05\n",
            "Epoch 76/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9625 - loss: 0.2029 - val_accuracy: 0.8896 - val_loss: 0.3648 - learning_rate: 1.0000e-05\n",
            "Epoch 77/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9602 - loss: 0.2037 - val_accuracy: 0.8937 - val_loss: 0.3665 - learning_rate: 1.0000e-05\n",
            "Epoch 78/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9599 - loss: 0.2033 - val_accuracy: 0.8896 - val_loss: 0.3653 - learning_rate: 1.0000e-05\n",
            "Epoch 79/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9598 - loss: 0.2052 - val_accuracy: 0.8896 - val_loss: 0.3649 - learning_rate: 1.0000e-05\n",
            "Epoch 80/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9596 - loss: 0.2065 - val_accuracy: 0.8896 - val_loss: 0.3650 - learning_rate: 1.0000e-05\n",
            "Epoch 81/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9612 - loss: 0.2071 - val_accuracy: 0.8875 - val_loss: 0.3651 - learning_rate: 1.0000e-05\n",
            "Epoch 82/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9612 - loss: 0.2023 - val_accuracy: 0.8896 - val_loss: 0.3658 - learning_rate: 1.0000e-05\n",
            "Epoch 83/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9627 - loss: 0.1997 - val_accuracy: 0.8855 - val_loss: 0.3648 - learning_rate: 1.0000e-05\n",
            "Epoch 84/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9614 - loss: 0.2058 - val_accuracy: 0.8875 - val_loss: 0.3654 - learning_rate: 1.0000e-05\n",
            "Epoch 85/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9620 - loss: 0.2037 - val_accuracy: 0.8896 - val_loss: 0.3656 - learning_rate: 1.0000e-05\n",
            "Epoch 86/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9591 - loss: 0.2059 - val_accuracy: 0.8896 - val_loss: 0.3656 - learning_rate: 1.0000e-05\n",
            "Epoch 87/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9663 - loss: 0.1999 - val_accuracy: 0.8896 - val_loss: 0.3660 - learning_rate: 1.0000e-05\n",
            "Epoch 88/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9638 - loss: 0.2009 - val_accuracy: 0.8937 - val_loss: 0.3670 - learning_rate: 1.0000e-05\n",
            "Epoch 89/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9612 - loss: 0.2023 - val_accuracy: 0.8896 - val_loss: 0.3665 - learning_rate: 1.0000e-05\n",
            "Epoch 90/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9577 - loss: 0.2064 - val_accuracy: 0.8896 - val_loss: 0.3669 - learning_rate: 1.0000e-05\n",
            "Epoch 91/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9626 - loss: 0.2024 - val_accuracy: 0.8896 - val_loss: 0.3674 - learning_rate: 1.0000e-05\n",
            "Epoch 92/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9672 - loss: 0.1999 - val_accuracy: 0.8896 - val_loss: 0.3670 - learning_rate: 1.0000e-05\n",
            "Epoch 93/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9642 - loss: 0.2000 - val_accuracy: 0.8855 - val_loss: 0.3666 - learning_rate: 1.0000e-05\n",
            "Epoch 94/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9589 - loss: 0.2071 - val_accuracy: 0.8896 - val_loss: 0.3672 - learning_rate: 1.0000e-05\n",
            "Epoch 95/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9640 - loss: 0.2012 - val_accuracy: 0.8896 - val_loss: 0.3678 - learning_rate: 1.0000e-05\n",
            "Epoch 96/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9638 - loss: 0.2028 - val_accuracy: 0.8855 - val_loss: 0.3671 - learning_rate: 1.0000e-05\n",
            "Epoch 97/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9634 - loss: 0.1999 - val_accuracy: 0.8896 - val_loss: 0.3678 - learning_rate: 1.0000e-05\n",
            "Epoch 98/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9592 - loss: 0.2083 - val_accuracy: 0.8896 - val_loss: 0.3677 - learning_rate: 1.0000e-05\n",
            "Epoch 99/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9630 - loss: 0.2009 - val_accuracy: 0.8896 - val_loss: 0.3677 - learning_rate: 1.0000e-05\n",
            "Epoch 100/100\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9645 - loss: 0.2005 - val_accuracy: 0.8855 - val_loss: 0.3675 - learning_rate: 1.0000e-05\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x795f6f399180>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = create_model()\n",
        "model.fit(train_seq_X_encoded.reshape(-1, 50, 10), train_seq_Y, validation_data=(val_seq_X_encoded.reshape(-1, 50, 10), val_seq_Y), epochs = epochs, batch_size=batch_size, callbacks=[reduce_lr])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDl07m2r7FvP"
      },
      "outputs": [],
      "source": [
        "model.save(\"trained_model_for_dataset_3.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gl3t0rDG8JWH",
        "outputId": "d6c384b9-94b8-4042-b5da-e6c8905038a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.885480572597137"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "model3 = tf.keras.models.load_model('trained_model_for_dataset_3.keras')\n",
        "y_pred = model3.predict(val_seq_X_encoded.reshape(-1, 50, 10))\n",
        "y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "accuracy_val = accuracy_score(val_seq_Y, y_pred_binary)\n",
        "accuracy_val"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}